{"cells":[{"cell_type":"code","execution_count":null,"id":"7dd6752e-fcd1-4eb3-af13-6bc2acc0d188","metadata":{"id":"7dd6752e-fcd1-4eb3-af13-6bc2acc0d188","outputId":"2be4cabb-b63e-479b-925f-3f41f732d253"},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to C:\\Users\\Saki\n","[nltk_data]     Nithi\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to C:\\Users\\Saki\n","[nltk_data]     Nithi\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package wordnet to C:\\Users\\Saki\n","[nltk_data]     Nithi\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     C:\\Users\\Saki Nithi\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n","[nltk_data]       date!\n","[nltk_data] Downloading package maxent_ne_chunker to C:\\Users\\Saki\n","[nltk_data]     Nithi\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n","[nltk_data] Downloading package words to C:\\Users\\Saki\n","[nltk_data]     Nithi\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package words is already up-to-date!\n"]},{"name":"stdin","output_type":"stream","text":["Enter the text to summarize:\n"," Cloud Computing:  The computing trend moved toward cloud from the concept of grid computing, particularly  when large computing resources are required to solve a single problem, using the ideas of  computing power as a utility and other allied concepts. However, the potential difference  between grid and cloud is that grid computing supports leveraging several computers in  parallel to solve a particular application, while cloud computing supports leveraging  multiple resources, including computing resources, to deliver a unified service to the end  user.  In cloud computing, the IT and business resources, such as servers, storage, network,  applications, and processes, can be dynamically provisioned to the user needs and  workload. In addition, while a cloud can provision and support a grid, a cloud can also  support nongrid environments, such as a three-tier web architecture running on traditional  or Web 2.0 applications. \n","Specify the length of the summary (short, medium, long):\n"," medium\n"]},{"name":"stdout","output_type":"stream","text":["\n","Summary:\n"," Cloud Computing:  The computing trend moved toward cloud from the concept of grid computing, particularly  when large computing resources are required to solve a single problem, using the ideas of  computing power as a utility and other allied concepts. In cloud computing, the IT and business resources, such as servers, storage, network,  applications, and processes, can be dynamically provisioned to the user needs and  workload. In addition, while a cloud can provision and support a grid, a cloud can also  support nongrid environments, such as a three-tier web architecture running on traditional  or Web 2.0 applications.\n"]}],"source":["import nltk\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize, sent_tokenize\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from nltk.stem import WordNetLemmatizer\n","import string\n","import numpy as np\n","\n","# Download necessary NLTK resources\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","nltk.download('averaged_perceptron_tagger')\n","nltk.download('maxent_ne_chunker')\n","nltk.download('words')\n","\n","# Initialize lemmatizer\n","lemmatizer = WordNetLemmatizer()\n","\n","def clean_text(text):\n","    # Lowercase the text and remove punctuation\n","    text = text.lower()\n","    text = text.translate(str.maketrans('', '', string.punctuation))\n","    return text\n","\n","def lemmatize_words(words):\n","    return [lemmatizer.lemmatize(word) for word in words]\n","\n","def summarize_text(text, summary_length='short'):\n","    cleaned_text = clean_text(text)\n","    sentences = sent_tokenize(text)\n","\n","    # Lemmatize words and tokenize\n","    words = word_tokenize(cleaned_text)\n","    lemmatized_words = lemmatize_words(words)\n","\n","    # Remove stopwords\n","    stop_words = set(stopwords.words('english'))\n","    filtered_words = [word for word in lemmatized_words if word.isalpha() and word not in stop_words]\n","\n","    # TF-IDF vectorizer\n","    vectorizer = TfidfVectorizer()\n","    tfidf_matrix = vectorizer.fit_transform(sentences)\n","    feature_names = vectorizer.get_feature_names_out()\n","\n","    # Sentence scoring using TF-IDF\n","    sentence_scores = {}\n","    for i, sentence in enumerate(sentences):\n","        score = 0\n","        sentence_tokens = word_tokenize(clean_text(sentence))\n","        lemmatized_sentence = lemmatize_words(sentence_tokens)\n","\n","        # Score sentence based on word importance\n","        for word in lemmatized_sentence:\n","            if word in feature_names:\n","                word_index = feature_names.tolist().index(word)\n","                score += tfidf_matrix[i, word_index]\n","\n","        # Normalize score by sentence length\n","        sentence_scores[sentence] = score / len(sentence_tokens) if len(sentence_tokens) > 0 else 0\n","\n","    # Determine the number of sentences to include in the summary\n","    if summary_length == 'short':\n","        num_sentences = 1\n","    elif summary_length == 'medium':\n","        num_sentences = 3\n","    elif summary_length == 'long':\n","        num_sentences = 5\n","    else:\n","        raise ValueError(\"Invalid summary length. Choose 'short', 'medium', or 'long'.\")\n","\n","    # Sort sentences by score\n","    sorted_sentences = sorted(sentence_scores, key=sentence_scores.get, reverse=True)\n","\n","    # For short summaries, select the most representative sentence\n","    if summary_length == 'short':\n","        # Select the highest scoring sentence\n","        summary = sorted_sentences[0]\n","    else:\n","        # For medium and long summaries, select the top sentences\n","        summary = ' '.join(sorted_sentences[:num_sentences])\n","\n","    return summary\n","\n","if __name__ == \"__main__\":\n","    text = input(\"Enter the text to summarize:\\n\")\n","    summary_length = input(\"Specify the length of the summary (short, medium, long):\\n\").lower()\n","    summary = summarize_text(text, summary_length)\n","    print(\"\\nSummary:\\n\", summary)"]},{"cell_type":"code","execution_count":null,"id":"df601ed6-a8c5-47e8-af46-2889ab756e7d","metadata":{"id":"df601ed6-a8c5-47e8-af46-2889ab756e7d"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}